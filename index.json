[{"authors":null,"categories":null,"content":"    You wanna experience VR space with pets? A completely new VR experience was born. If you wear this new VR headset, you can walk a foreign city with your pet. The difference from the VR experience so far is that pets can also wear VR goggles and pets can also experience a totally different place taking a walk. In addition, you can exchange your vision and pet\u0026rsquo;s vision. You can take a walk as if you were a pet, and a pet as if you were an owner. Please try experiencing this completely new VR.\nHuman\u0026rsquo;s view   Dog\u0026rsquo;s view   ","date":1542603600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542603600,"objectID":"d5a523e727ffb5e8d9aacd68f3b7fd69","permalink":"/parsons/vrtrip1/","publishdate":"2018-11-19T00:00:00-05:00","relpermalink":"/parsons/vrtrip1/","section":"parsons","summary":"Berlin/Paris VR Trip","tags":null,"title":"Berlin: Animal Imitation","type":"parsons"},{"authors":null,"categories":null,"content":" Final Statement Problem (Why) There are things which we cannot do by myself.\nSolution (What) Use recursive power to do it by myself   Design Process Brainstorming       \nConcept 1       \n  Concept 2       \n  Concept 3       \n  Feedback and Update     \n      ","date":1542171600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542171600,"objectID":"76d0dd91112b678ea54848a6dc33829a","permalink":"/ms1/intent2/","publishdate":"2018-11-14T00:00:00-05:00","relpermalink":"/ms1/intent2/","section":"ms1","summary":"Final Project Statement","tags":null,"title":"Updated Intent for Final","type":"ms1"},{"authors":null,"categories":null,"content":" Context - Domain 1 Network Science The first domain I want to research is Network Science. When I reviewed my exploration so far, I found I am interested in creating a network in any kind of way. For example, in 2D and 4D, I tried to create a network and connect people based on background careers or question-answer conversation. Previously I said that my domain is social computing, however, social computing was still broad and it was more intriguing for me to see it from the perspective of the network.  \nActually network science covers very broad area because in the current our world, we are surrounded by bunch of networks such as hypertext, social network and transportation network and so on. I\u0026rsquo;m interested in what is networked and not networked, and what will happen if stand-alone things such as subjective feelings and body signalsare networked.  \nContext - Domain 2 Affective Interaction In 3D - 5D, I tried to implement the interaction through affective questions that can only be answered by people. Affective computing is one of the representative area of this field and researching development of systems and devices that can recognize, interpret, process, and simulate human affects. However, I want to focus on not an emotion recognition technology itself but an application of human affects as a designer.  \nCreative Precedents Penal Systems Network Penal Systems Network is a relational mapping of world’s penal systems that evoke controversy: A network map of world countries connected to juridical topics whether or not they are being exercised and how they are being exercised such as death penalty, life imprisonment, parole, indefinite sentence, and amnesty.\nContext: Make a network of domestic data  \nFeel-o-meter Fuehlometer (Feel-o-meter) is an interactive art installation that shows the mood of a city by displaying it in the form of a monumental Smiley. The system allows to read emotions out of random people’s faces. The faces are analyzed by sophisticated software (contributed by the Fraunhofer Institut). The obtained mood data are then stored on a server and processed by the smiley to visualize the emotions in real-time.\nContext: Assemble moods of the city   LAUREN. A human smart home intelligence. This project attempts to become a human version of Amazon Alexa, a smart home intelligence for people in their own homes. The artist Lauren remotely watches over the person 24\u0026frasl;7 and controls all aspects of their home. Lauren aims to be better than an AI because she can understand them as a person and anticipate their needs. The relationship that emerges falls in the ambiguous space between human-machine and human-human.\nContext: Make a network and relationship between people who do not know each other  \nelectric stimulus to face Daito Manabe experimented how might we control our face electrically.\nContext: Make a network of body signals   The Stack In The Stack, Benjamin Bratton proposes that these different genres of computation—smart grids, cloud platforms, mobile apps, smart cities, the Internet of Things, automation—can be seen not as so many species evolving on their own, but as forming a coherent whole: an accidental megastructure called The Stack that is both a computational apparatus and a new governing architecture. We are inside The Stack and it is inside of us. In an account that is both theoretical and technical, drawing on political philosophy, architectural theory, and software studies, Bratton explores six layers of The Stack: Earth, Cloud, City, Address, Interface, User. Each is mapped on its own terms and understood as a component within the larger whole built from hard and soft systems intermingling—not only computational forms but also social, human, and physical forces. This model, informed by the logic of the multilayered structure of protocol “stacks,” in which network technologies operate within a modular and vertical order, offers a comprehensive image of our emerging infrastructure and a platform for its ongoing reinvention.\nContext: Devide network into layers\n  BeeMe This Halloween scientists at MIT\u0026rsquo;s Media Lab are embarking on a massive social experiment. Called BeeMe, the project will let internet users control a real human actor, suggesting, and collectively voting on, this person\u0026rsquo;s every action. New Atlas reached out to Niccolo Pescetelli, one of the creators behind the experiment, to find out exactly what is about to happen.\nContext: Make a collective decision and control human  \nDesign Questions and Concepts so far Creative Questions In this research, I came up with the following creative questions.\n What will happen if stand-alone things such as subjective feelings and body signalsare networked?  What happens when objects are networked? Can you synthesize or disassemble it?  How might we assemble individual affects and utilize them for individuals again?  How will rewards and erroneous information affect collective decisions? How much will a person\u0026rsquo;s free will be affected by the collective will?   Concepts  Decompose network elements Networked body signal Use network as a medium of art Control virtual challacter by collective decision Visualize traffic of each layer of Stack (City, Earth and so on)  Discuss in the class Discuss with Jerry and Karen One of Jerry\u0026rsquo;s domain collective creation was similar to my domain. He was interested in collecting body signals and turning into some information, and I also curious about collecting emotions of the human. We discussed how to deal with elements of the interaction. Our common factors of interaction are people and the environment, and we debated what input and output we should use. I referred to some precedents Jerry had, and I found some interactions treated everybody equal, and the other one visualized information according to a person\u0026rsquo;s body heights. So the insight of discussion with Jerry was we can give a different look and feel according to how to handle input and output. However, Karen pointed out that we were going into discussions of implementation deeply, and we found we should discuss \u0026ldquo;why\u0026rdquo; perspective. Human augmentation, one of Karen\u0026rsquo;s domain, is also related to my domain. Our common aim is to expand the human\u0026rsquo;s perception. In discussion with Karen, I found I need to think about substantial problems from the perspective of the user and write down the question as the form of \u0026ldquo;How might we - ?\u0026rdquo; Finally, I came up with the question \u0026ldquo;How might we make a network of countries\u0026rsquo; happiness to compare with standards of happiness?\u0026rdquo; in the discussion. But I thought my question still needed strong \u0026ldquo;why\u0026rdquo;. So I need more resarch to create future vision of network and human augmentation.\nMore Precedents Mutual Human Actuation Human actuation is the idea of using people to provide large-scale force feedback to users. The key idea is to run pairs of users at the same time and have them provide human actuation to each other.\nI came up with one question from this work: How might we connect activities which are completely different but mutualy complementary?\n  Sense-Roid: Emotional Haptic Communication with Yourself What type of emotions could be obtained if you were able to hug yourself?   Fight with myself In a Japanese geek blog, a father made a system which decreases the time of changing his child\u0026rsquo;s cloth. The problem for this father was that his child often takes time to change his cloth in the busy morning. So he projected images of the child\u0026rsquo;s changing cloth in the past and let him compete with himself in the past. In this kind of way of gamification, his child thought he didn\u0026rsquo;t want to lose to himself and became to change his cloth as quickly as possible.\nI came up with one question from this work: How might we make a network with ourselves in the past to improve ourselves?\u0026lt;  \nUpdated Questions and Concepts How might we connect activities which are completely different but mutualy complementary?  For example, if there is a person somewhere who wants to push objects and there is a person who wants to draw some object at the same time, can we connect those activities that are totally individually occurring and make mutually complementary relationships?  How might we make a network with ourselves in the past to improve ourselves?  In life, the most challenging enemy is myself. To keep improving, can we make a connection with ourselves in the past via some kind of inormation?  Direction of Prototype Seek activities which are completely different but mutualy complementary Seek a valuable information to track for keeping improving myself  the time to turn off the light of the bedroom  ","date":1540872000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540872000,"objectID":"cf2c7cf16eae1e128409aa58830c576e","permalink":"/ms1/intent/","publishdate":"2018-10-30T00:00:00-04:00","relpermalink":"/ms1/intent/","section":"ms1","summary":"Final Project Statement","tags":null,"title":"Intent for Final","type":"ms1"},{"authors":null,"categories":null,"content":" Project Overview Current research (source) shows that subway and bus ridership has declined while ridership through ride-sharing services like Lyft and Uber has increased. App-based services are based on a great UX and are increasing their users dramatically.\nTherefore, to increase a retention rate, MTA needs to provide the user-centered service for the purpose of getting access easily to the metro, on time, without having a bad experience.\n Data: Transportation Trends in NYC   From interviewing with real users, it turned out that NYC commuters sometimes have a frustration that they want to catch a train but cannot because they don\u0026rsquo;t have enough money in the metro card. In this moment, they have to go back to a ticket vending machine and wait in a long line to refill your card. This is really frustrating and painful experience.\n  To solve this problem, I developed the idea of smart metrocard which enables users to refill the money anytime and anywhere. Subway users can refill money through the App and enter the platform without using a ticket vending machine.\n Smart Metrocard   This proposal is a little bit radical because the physical metrocard also need to be intelligent in order to reflect real-time refilling money from the App. However, this smart metrocard infrastructure is adopted by many countries such as Germany, France and Japan, and they don’t have a frustration of purchasing train tickets. \nResult In this design challenge, I conducted the user interview using the invision mockup, basic function is accepted by the user and we can plan a next iteration.  \nMy Role I conducted the whole design process from interviewing with users, defining problem, ideation, prototyping and evaluation.\nDesign Process New York city commuters are primary user group and travelers are second user group because they are the biggest user groups.\nFrom my research, there are 1.5 million daily-use commuters in NYC and over 60 million temporary-use traveller in a year. Also, they’re creating over $500M per month in total. They account for the majority of MTA\u0026rsquo;s revenue.  \nInterviewing with a real user and confirming our assumption at the beginning is the fastest way to define problems.\nI conducted interviews with 3 friends of mine. 2 of them are commuters and other 1 is traveller. I confirmed their process to use the subway and extracted their pain points from this interview.\nI found commuters have frustration especially in rush hour. They hate time consuming to make a line to refill a metrocard and crowded train. Also, travellers have a trouble to sightseeing. They feel the entrance is narrow for big suitcase, time is not accurate and platform is dirty.\nFinally, I converged the pain points and categorized 3 main frustration area from the interview. This is the problem related to ticket machines, platform and train schedule. These areas needs to be solved.\n        \nBased on the specified pain points and directions, I conducted the brainstorming and created bold ideas. I came up with 10 following ideas.\n Touch \u0026amp; Go by smartphone Gateless entry Fingerprint entry Refill using App Free wifi spot Library in the platform Bigger entrance visualize maintenance status visualize realtime train operation status visualize real train location on the map            --\nI think the prioritization is the most important part because we must decide the solution and discard other solutions in this timing.\nIn this time, I used the prioritization grid which I used in my IBM career. This grid has 2 axis. One is desirability for the user and the other is feasibility in terms of technology and business. Using this 2 axis, we can evaluate the idea from design, business and technology.\n  I arranged the idea using this chart and decided to pick up the idea that is in the No-Brainer area. I finally chose the \u0026ldquo;Refill using App\u0026rdquo; idea because there is other competitors in the other idea in the No-Brainer area.\n  After defining the solution, I moved to the implementation phase. I drew the storyboard, content map and wireframes. My policy is drawing an experience in the storyboard. It should not be functional because it verifies the experience we\u0026rsquo;re thinking. For me, the prototype is a work to improve the resolution from 1 shot idea, 6 shots storyboards, to an interactive mockup.      \nSolution Smart Metrocard App    After prototyping, I conducted the user interview using the invision mockup because of the limited timeline. However, project success is measured by both quantitative and qualitative to judge properly.\nIn terms of quantitative perspective, we can test the time to refill money via App compared with making a line in front of a vending machine. We need to evaluate practical effects of the project using quantitative data. Also, in terms of qualitative measure, user interview should be conducted in the evaluation stage. I can confirm more emotional effects for the user.   Learning When I work in a project, I think the following two part is the most important.\nOne is defining the right problem because it is meaningless to solve the wrong problem. In this project, I conducted several user interviews to explore the problem and verify our assumption. Going out of the office and listening to the voice of real users is the start point of the project.\nThe other is making as soon as possible trying multiple iterations. We cannot deliver a perfect product in the first iteration. We need to continue quick prototype and validate the experience in each time. In this project, I couldn’t take enough time to continue iterative cycles because of the limited timeline, but I need to manage at least 2 prototyping cycles to improve the final quality.\nDesign Timeline    Project Type  Private | UX Design Challenge  Phase / Period  Empathize, Define, Ideate, Prototype, Test 10 / 2018 (40h)  Team  Sole Project  Method / Technology  User-Centered Design Target Device: iOS App   ","date":1540612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540612800,"objectID":"eb0ad24ad5a06466066da9301f85334f","permalink":"/project/2018_mta/","publishdate":"2018-10-27T00:00:00-04:00","relpermalink":"/project/2018_mta/","section":"project","summary":"Redesigned a NYC Metrocard experience to free subway users from making a line to refill the card.","tags":["uxui"],"title":"MTA Smart Metrocard","type":"project"},{"authors":null,"categories":null,"content":" Project Overview In 2016, new policy of deregulation of the electricity industry in Japan has begun, and a lot of new and emerging companies and startups have entered the electricity market and acquire users by user-centric services. C-EP must shift to a client first company and provide user-centered services in order to improve its retention capability.  \nC-EP is supporting lives of families and we decided a dual-income working mother as a primary user. In Japan, 49% of households are dual-income families in urban area and It is expected that this figure will continue to rise in the future.\nAccording to many interviews with working mother, we found how hard working parents take care of little children. When a working mother comes back to the home, she must do many houseworks with taking care of children. And finally we found 2 core insights we should tackle with.\nOne is the problem that recent mothers often handed out a smartphone to a child when they were busy and showed YouTube and animation. It causes less communication between parents and children. Also, some young mothers even lose a way how to take care of children. They feel guilty to rely on a smartphone, but they can not quit it.  \nThe other insight is mothers doesn\u0026rsquo;t know children\u0026rsquo;s feelings and preferences well. According to our interview, even mothers who are communicating with children usually say that they do not understand children\u0026rsquo;s feelings.  \nWith iterative prototyping in collaboration with C-EP members, I regarded working mothers to rely on smartphones as a new habit and turn it into positive activities.\nWe developed an iOS app that can communicate with children when parents handed out a smartphone to them. By recording their daily responses and sharing these with parents, the family members are able to understand the children’s hidden feelings and preferences.\n  I and my team designed and finalized 94 screens and interactions in the development phase. we cultivated a new paradigm of customer service that tightens family bonds using iPhone.\n  Result After the implementation. we performed a qualitative and quantitative user evaluation. 234 dual-income households with children tested this App for 2 weeks, and 75% of people evaluated \u0026ldquo;Good (55%)\u0026rdquo; and \u0026ldquo;Very Good (20%)\u0026rdquo; against the whole concept. Therefore, the client decide to launch this App in the next year cycle with considering qualitative feedback comments. Currently, the client continues to develop Android version and they are planning to release this product in 2018.\nThe items of evaluation is the following (according to AARRR model):\n Quantitative survey  Do you sympathize with the concept? Do you want to download and use this application?  Qualitative comments  What are the pros and cons of this application? Is there any other feature you want?  Analysis of data log  Which function was most used? Which function kept being used most?   My Role As a project manager and professional UX designer, I contributed to the project from the concept phase to the agile development phase. In terms of technology, customer experience and sustainable business model, my team designed entire new business ecosystem of the client.\nIn the concept phase, I planned a Design Thinking workshop with clients and created the initial concept of the service, prior to narrowing this down to a series of actionable steps in consideration of the concept’s implementation. Additionally, in the subsequent development phase, I have worked on continuously improving the quality of the product through a process of iterative prototyping and user evaluation. I am certified as both a practitioner of IBM Design Thinking and a Scrum Master, which means I can work consistently end to end, from the concept creation to the implementation phases, as a professional user experience designer.\nDesign Process At the beginning, in the concept phase, we planned 2-days IBM Design Thinking workshop with clients, created the initial concept for a new service. We divided the members into 2 teams (personas) and eventually created 6 promising concepts.                      \nDefine User and Service Direction Visualized and verified customer experience -- From these bold ideas, we narrowed down the concept by repeated 10 interviews and finally created 2 user scenarios and static mockup screens.  \n         -- Customer Journey Map    Working mother Scenario         Paper Prototype     \nConcept Visual  --   Lean Startup: Explored requirements of business model, UX and tech specs In the following lean startup phase, we specified and verified business opportunities and appropriate user experiences. Collaborating with business strategists and engineers, we created the detailed service ecosystem in terms of business, technology and design.  \nCo-Creation: Collaborated with users, clients, business strategists and technologists We performed 30 interviews and improved our product iteratively. Using InVision, we performed interviews with a moving prototype mockup. Finally, we fixed requirements of comprehensive services and proceeded to the following development phase.  --     \nPrototype 1 Using Invision, we designed mockup screens to interview. The following charts are parts of designed mockup screens.      --\nWalkthrough from Business and Technology side Updated Journey Map considering the business model and technical feasibility    --    \nFix MVP UX/UI Specifications and Proceed to the development phase         Final Wireframe \u0026amp; Flow Finalized UX/UI in sprints of development In the subsequent development phase, I have been working on continuously improving the quality of the product through a process of iterative prototyping and user evaluation. I have the certification of both a practitioner of IBM Design Thinking and a Scrum Master, so I can work consistently end to end from the concept creation to implementation phases as a professional user experience designer.\nFinally my team designed and finalized 94 screens and interactions in the development phase.   \nLearning I think service Design is Co-creation. Product design is a process of exploring an appropriate ecosystem comprising everyone, that is created by everyone, and is provided for everyone.\nMy guiding principle is co-creation with clients, users, stakeholders, and experts to advance the journey between ideal concept and viable function; innovation and cliché; and provider’s aspiration and the customer’s need.  \nDesign Approach Design Thinking + Lean Startup + Agile Development Observation and empathy for users are the starting point.  -- Using design thinking, while focusing on customer-oriented thinking, we define the strong concept eventually to be released as a service running in the society. With the concept of lean startup, we verify and grow the service concept as a feasible business model. Finally we implement the business ecosystem designed with such a way of thinking to the world with agile development.  \nDesign Timeline    Phases / Period  Concept, Design, Build 02/2017 - 01/2018  Method  User-Centered Design, Agile engineering, Lean Startup Target Device: iOS App  Product Release  11\u0026frasl;2018 (plan)   ","date":1540353600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540353600,"objectID":"4cdcec57112164531e9e68248e118528","permalink":"/project/2017_cepco/","publishdate":"2018-10-24T00:00:00-04:00","relpermalink":"/project/2017_cepco/","section":"project","summary":"Created a new paradigm of service ecosystem that tightens family bonds","tags":["uxui","service"],"title":"C-EP CONSUMER SERVICES","type":"project"},{"authors":null,"categories":null,"content":" Project Overview We called with Sam Eldersveld, Director of Operations Research at Uber, and we learned that Uber thought the perfect pickup is the most important factor of the User Experience. The moment of pickup is when the driver and the rider meet for the first time. Both drivers and riders are nervous and frustrating in this moment because drivers want to finish the work without trouble and riders want to get to the destination quickly. If the entrance of this interaction is uncomfortable, the subsequent ride experience will also be unpleasant.\n Interview Material   We conducted our field research at JFK airport. It is one of the places where perfect pickup is difficult because of crowed cars and peoples, complicated terminal numbers and exits.\nAccording to the field research, the problem is that Uber drivers have a language problem in the airport ride because sometimes passengers cannot speak English. This causes unjustifiable low ratings of drivers.\n Field Research and Interview with the Driver   From gained insights of field research, we developed a user flow and mockup screens.\n  To-Be User Journey Map    One of features: Automatic Translation  \nResult Our team pitched our research and mockups to the class and really valuable feedback around the viability of our solutions. The feedback to focus on the functionality and flow of the driver interface is reflected in the iterations that have been made on this document.    \nMy Role I conducted interviews with Uber drivers, conducted secondary research, developed personas, project management, synthesis, concept/use case design, and designed the presentation narrative.\nDesign Process My team conducted both secondary research and ethnographic research. Considering the time constraints of the course, all of our research was qualitative.\n  Once we arrived to JFK Airport, we used AEIOU (Activities, Environments, Interactions, Objects, Users) templates as a framework to gather notable findings and we recorded all interactions and experiences we had.  \n  Also, we interviewed with a real driver how to do his work usually. We negotiated an untraditional ride: circling around the JFK airport for a 20 minute interview session.\nIn the interview, we confirmed that he had a problem to pick up a rider in the airport. Our driver told that he had a mistake that he picked up the wrong person who has a same first name because this passenger was so in a hurry. Also, he had a language problem because sometimes people who cannot speak English ride especially in the airport. We understood how difficult to pick up a right person perfectly.\n  After the interview, we debriefed our findings and designed a persona based on our talk with the driver. Just to note, there are other personas within the Uber driver community (young, single, female, temporary, etc). In the context of perfecting the pickup at JFK airport, solutions should be applied to all Uber drivers.\n      We met after classes to conduct brainstorming and create solution. A few themes we began to build upon:\n The driver has a language problem when the passenger cannot speak English The driver sometimes cannot recognize the accurate pickup location    After the ideation, we began to segment the Uber driver journey to visualize the complete end to end experience and look for opportunities to optimize the pickup process. We also designed a journey map for the passenger side as well.\n    Solution Free from language barriers         \nLearning I think user interview needs not just a talking skill but a well-prepared strategy. To have a good preparation enables us to extract a good insight from user.\nIn this class, the professor told us these strategies of interview. For example, we should go to interview with at least 3 people and devided the role separately. One focus on the interview, another one focus on the minutes, and the final one focus on recording. It means interviewing is not only just a talking, but also a strategic activity. Another strategy is to prepare questions beforehand. To think about why we ask this question and what we want to extract is the most important part of the interview. Without these thinkings, our interview will be lost the way.\nDesign Timeline    Project Type  Academic Company: Uber Instructor: Jodi Leo, VP of Product Design at CapTap Class: Research Methods  Phase / Period  Concept 07/2015 - 08/2015  Team / Role  Sandra Gatica Morales, Colleen Brogan UI/UX Design Practitioner  Method / Technology  User-Centered Design Target Device: Mobile  Tasks  Interviews, User research, UX Design, Acquisition design  Output  Sketches ( design iterations and user flows) Interview Footage, Synthesis, and Findings User Acquisition research Design and functionality recommendations proposal deck Final assets (presentation poster board)   ","date":1540094400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540094400,"objectID":"2991405f954e3bb35f4e0006e875cbc1","permalink":"/project/2015_uber/","publishdate":"2018-10-21T00:00:00-04:00","relpermalink":"/project/2015_uber/","section":"project","summary":"Designed a new feature for UBER drivers in the SVA Summer Interaction Design Program","tags":["uxui"],"title":"UBER UX RESEARCH AND DESIGN","type":"project"},{"authors":null,"categories":null,"content":"Masaki is an interaction and service designer based in NY. His work examines the reciprocal relationships between science, technology and their influence on human identity, subjectivity, and collective culture. He holds the MFA degree in Design and Technology at Parsons School of Design. Previously he worked at IBM for 10 years as a UX designer.\n","date":1539921600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539921600,"objectID":"8f712dfc624bba5bed8bb6f92ec3ccfa","permalink":"/ms1/career/","publishdate":"2018-10-19T00:00:00-04:00","relpermalink":"/ms1/career/","section":"ms1","summary":"My biography in 2020","tags":null,"title":"Biography","type":"ms1"},{"authors":["Masaki Iwabuchi"],"categories":null,"content":"","date":1539921600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539921600,"objectID":"cf878c0a6fd25269627331541eb29db6","permalink":"/publication/manifesto/","publishdate":"2018-10-19T00:00:00-04:00","relpermalink":"/publication/manifesto/","section":"publication","summary":"The transition from an incremental advancement based on Human-Centered Design to a radical mutation based on Alien-Centered Design.","tags":[],"title":"Design Manifesto: Goodbye Human, Hello Alien.","type":"publication"},{"authors":null,"categories":null,"content":" Observation, Research, Ideation                                       \nPrototype                 \nTest: Iteration 1       \nTest: Iteration 2       \nTest: Iteration 3       \nTest: Iteration 4       \nFuture Iteration   ","date":1539576000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539576000,"objectID":"badcaec85ac79bf06a5d8bff2a7ef5b0","permalink":"/ms1/highline/","publishdate":"2018-10-15T00:00:00-04:00","relpermalink":"/ms1/highline/","section":"ms1","summary":"Public Intervention Project","tags":null,"title":"MJ Button","type":"ms1"},{"authors":null,"categories":null,"content":"                    \n","date":1538283600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538283600,"objectID":"edb9ee8eff8771db4aa7ac7514e04c36","permalink":"/ms1/5d/","publishdate":"2018-09-30T01:00:00-04:00","relpermalink":"/ms1/5d/","section":"ms1","summary":"Explore ideas in form (5D)","tags":null,"title":"5D: Collective Transition","type":"ms1"},{"authors":null,"categories":null,"content":"                \n","date":1538280000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538280000,"objectID":"966a4566e50bbe1e499ed6fdeab27914","permalink":"/ms1/4d/","publishdate":"2018-09-30T00:00:00-04:00","relpermalink":"/ms1/4d/","section":"ms1","summary":"Explore ideas in form (4D)","tags":null,"title":"4D: Collective Aroma","type":"ms1"},{"authors":null,"categories":null,"content":"                \n","date":1538193600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538193600,"objectID":"3129d68ddbe44f137b8b3506f83028d9","permalink":"/ms1/3d/","publishdate":"2018-09-29T00:00:00-04:00","relpermalink":"/ms1/3d/","section":"ms1","summary":"Explore ideas in form (3D)","tags":null,"title":"3D: Collective Juice","type":"ms1"},{"authors":null,"categories":null,"content":" Overview Demo Video   Project Information  Phase / Period  Concept, Design, Build, Evaluate 10 / 2018 (4 weeks)  Team  Researcher(Me), Professor Harpreet Sareen  Method / Technology  Ideation from 1D to 5D Arduino, processing  Output  Physical prototype   Objective How might we collect responses to questions that can only be answered by humans? As the development of technology, we can find many answers online within just a second. Have we ever wondered how the other people think about the same question? Have we ever wondered what it looks like after collecting different opinions together?\n  Concept Convert people\u0026rsquo;s emotions into collective mood of the group/community   Design Decision  What kind of question is appropriate?  Use an open question to confirm the difference between a collective opinion and a subjective opinion and to ask a more social question.  How to answer the question?  Decide to use easy yes/no question to create a first running mockup quickly. Types of quesitions and responding formats can be changed later.  How to visualize answers?  More intuitive way is appropriate such as color or size. Decided to explore a tangible format because data visualization on the screen is being implemented in many cases. Sought a different perspective by outputting data that is usually visualized visually to different sensory such as taste.  Is there a business impact?  Realize the experience of tasting a mood of the day and expect commercialization as a drink of the \u0026ldquo;mood\u0026rdquo;.   Implementation \u0026amp; Evaluation Physical Prototype Using arduino and processing, I implemented the physical prototype.  \nEvaluation   Future Iteration I am planning to improve it using actual juice and demonstration in public spaces and facilities.\n Platform to collect public opinion  It can be used as a platform to visualize the current mood of cities, facilities and communities. We can compare how much mood of real-time people is different according to region and location.  Collect more diverse emotion  Human emotion is more than just positive or negative. It can added more diversity emotions such as sad, exhausted and happy.     Design Process Ideas in Form   Credit  This project is carried out in the class of MAJOR STUDIO 1 by Herpreet Sareen.\n ","date":1538020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538020800,"objectID":"4f372f9b28f84678203bb448aa4b6c41","permalink":"/project/2018_collective/","publishdate":"2018-09-27T00:00:00-04:00","relpermalink":"/project/2018_collective/","section":"project","summary":"Designed an interaction that collects people's emotions and visualie them as an collective juice.","tags":["product","code"],"title":"Collective Juice","type":"project"},{"authors":null,"categories":null,"content":"                              \n","date":1537761600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537761600,"objectID":"6c7769a8f28e669272409b9ca7a28db6","permalink":"/ms1/2d/","publishdate":"2018-09-24T00:00:00-04:00","relpermalink":"/ms1/2d/","section":"ms1","summary":"Explore ideas in form (2D)","tags":null,"title":"2D: Career Chain","type":"ms1"},{"authors":null,"categories":null,"content":"                                  \n","date":1537416000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537416000,"objectID":"85f60724e7da30d7a922c51e80d2b935","permalink":"/ms1/1d/","publishdate":"2018-09-20T00:00:00-04:00","relpermalink":"/ms1/1d/","section":"ms1","summary":"Explore my domain by writing a story","tags":null,"title":"1D: Identiy Digitalizing","type":"ms1"},{"authors":null,"categories":null,"content":"I picked up an umbrella for critiquing as an interface. An umbrella or parasol is designed to protect a person against rain or sunlight. It is said that an umbrella has been used about 4000 years ago and remains in sculptures such as Egypt, Persia, and mural paintings. In many regions, umbrellas have developed to protect the king from sunlight, so they have long been a luxury item, a symbol of wealth and power.  \nThe umbrella of the current structure was developed as a parasol in the 18th century, and initially, it was a woman\u0026rsquo;s belongings. On rainy days the man was wet without a habit of having an umbrella, but eventually, the umbrella also spread to men. The context of the umbrella changes with the times and it is still used worldwide as an essential item of rain today.   Paris Street; Rainy Weather, by Gustave Caillebotte (1877)\nAs an interface between people and rain, an umbrella has a very long history. Although the context to be used has changed, the function and design almost unchanged for thousands of years. The shape of umbrella affords us to open, and I think that it is a complete form as a product.\nHowever, umbrellas have risks of being stolen or forgotten, hand clogging, wind weakness, etc. I think that there is a possibility of innovation using emerging technology. For example, an umbrella capable of tracking position information and a drone umbrella is undergoing demonstration experiments.  \nHowever, I focused on a project named \u0026ldquo;Song of Raindrop\u0026rdquo; that uses Arduino to convert energy when rain hits an umbrella into music.  \nIt is wonderful that this project is not for the current problem solving, it makes the rainy day more pleasant and also makes the context of rainy days change poetically. I would like to refer to this \u0026ldquo;augmented rainy day\u0026rdquo; idea regarding changing the context and making natural phenomena more interactive.\n","date":1535860800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535860800,"objectID":"25782e79df54bd56b139370500a3af9c","permalink":"/ms1/interface/","publishdate":"2018-09-02T00:00:00-04:00","relpermalink":"/ms1/interface/","section":"ms1","summary":"Critique for the umbrella","tags":null,"title":"Interface Critique","type":"ms1"},{"authors":null,"categories":null,"content":" Concept XHuman: Educational Headset for transhumans to Experience “Human” in 2075         \nProject Information  Phase / Period  Concept, Design, Build Period* 10\u0026frasl;2018 (2 weeks)  Team / Role  Researcher(Me), Professor  Method  Future Cone, Future\u0026rsquo;s Wheel, Timeline, Persona, Empathy Map, Storyboard, technological research\n  Output* Physical prototype, User\u0026rsquo;s Manual  Objective How can Humans and Transhumans coexist towards a sustainable society in 2075?   In 2075, this is the first generation that humans and transhumans are coexisting in the society. There is a new social problem that human beings and transhumans can not understand each other. Transhuman can not understand why humans are so inefficient. Humans were also afraid of transhuman beyond their abilities and did not know how to work or live together.\nPossible Timeline   In 2045, AI finally exceeded the intelligence of all human beings.\nIn 2060, superintelligence is embedded in the human brain for the first time and Human consciousness uploaded on the internet.\nNow in 2075, 11% of parents choose to implant AI to their newborn babies. They are the first generation of transhuman society.\nRecently transhuman-only school is established because their superintelligence and don’t need “normal” human’s curriculum anymore.\n  Design Approach Future speculation using wearable technology Create a speculative body technology that interacts with our sensory input or output. This device could enhance the way we see, limit our ability to smell or hear\u0026hellip;This device could be useful for a future version of our world, or another world/society from our imagination.\nMake a prototype of an object, along with user manual that illustrates how it works and how one would use it.\n  Design Process Future Speculation           \nCredit  This project is carried out in the class of SPECULATIVE SCIENCE FOR DESIGN FICTION by Deren Guler.\n ","date":1535083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535083200,"objectID":"47fc5a91a274802ab4c21951849684cc","permalink":"/project/2018_speculative/","publishdate":"2018-08-24T00:00:00-04:00","relpermalink":"/project/2018_speculative/","section":"project","summary":"Speculated and designed a wearable device for the society of post-singularity in 2075.","tags":["product","speculative"],"title":"HUMAN EXPERIENCE FOR TRANSHUMAN","type":"project"},{"authors":null,"categories":null,"content":"                                  \n","date":1534737600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534737600,"objectID":"24a70a3fa9f3ecb24c794544ae8e63c1","permalink":"/ms1/5in5/","publishdate":"2018-08-20T00:00:00-04:00","relpermalink":"/ms1/5in5/","section":"ms1","summary":"different 5 projects","tags":null,"title":"5 in 5 project","type":"ms1"},{"authors":null,"categories":null,"content":" Overview Demo Video   Project Information  Phase / Period  Concept, Design, Build 10 / 2018 (1 Day)  Team / Role  Sole Project Maker, Coder  Method / Technology  Iterative coding html5, css3, javascript, three.js [Link] Demo is here\n--               \n","date":1532664000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532664000,"objectID":"fd386a08e0930206b072b39a060fa098","permalink":"/project/2018_organic/","publishdate":"2018-07-27T00:00:00-04:00","relpermalink":"/project/2018_organic/","section":"project","summary":"Coded a sound visualizer which enables music experience more organic.","tags":["code","graphic"],"title":"ORGANIC MUSIC VISUALIZER","type":"project"},{"authors":null,"categories":null,"content":"           --                     \n","date":1493265600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493265600,"objectID":"eb4cd5aba42f9213b426bb2976edab34","permalink":"/post/2017_smile/","publishdate":"2017-04-27T00:00:00-04:00","relpermalink":"/post/2017_smile/","section":"post","summary":"Explored an intersection between photography and picture.\nExhibited in Japanese Gallery.","tags":["photo"],"title":"SMILE","type":"post"},{"authors":null,"categories":null,"content":" Overview Demo Video   Project Information  Phase / Period  Concept, Design, Build, Evaluate 04/2007 - 03/2009 (2 years)  Team / My Role  Researcher: Masaki Iwabuchi Professor: Takeshi Naemura (Professor of the University of Tokyo)  Method / Technology  Technology Research, Iterative Prototyping Touch Interface, Non-Organic Transparent EL Display, OpenGL  Output  Research Paper, User Evaluation Sheet   Inspiration What if we can display information on a transparent surface? Direct-touch input enables intuitive operation, and touch panels have been mounted on various devices. However, finger occlusion becomes one of the problems when a user touches the display from the front side. Here, inspired from SF movies, one idea to solve this problem is to use \u0026ldquo;transparent\u0026rdquo; display. Additionally, we can imagine various scenarios if we can display information on a transparent surface.  \nConcept Interaction from the rear side of the display With transparent surface users can operate from the rear side of the screen while seeing both displayed images and their fingers. This feature resolves a finger occlusion problem. Additionally, this feature works for multiple users. Two users can share an identical display from both sides and control displayed objects at one time. It will apply to a collaborative work and an entertainment application.  \nLearning Research through Design During this period, I developed a strong belief that an effective interchange between theory and practice is essential to advancing society. I obtained transdisciplinary feedback from both academia and the public on my academic poster and demonstrations for LimpiDual Touch, which revealed to me that visualized emerging technologies harbored a powerful ability to stimulate user imagination. I was especially intrigued by new questions raised by viewers and attendees, such as whether all future devices would utilize rear side input, or how the user experience would change if glass were replaced by a transparent display. To me, these inquiries were more important than new ideas for practical applications for the technology.  \nDesign Process Research through Design   Discourse Research and Problem Finding There have been several research projects that offer interactions by touching the rear surface of the device [Sugimoto and Hiroki 2006], [Wigdor et al. 2007]. However, the former prevents the user from seeing his hands; this sets up a new occlusion problem. As for the latter, the system size becomes large since a camera has to be attached outside the display. Our LimpiDual Touch has a simple hardware setting that allows the user to see his hands using an optically limpid display.\n WIGDOR, D., FORLINES, C., BAUDISCH, P., BARNWELL, J., SHEN, C. 2007. LucidTouch: A See-Through Mobile Device In Proceedings of UIST 2007, 269–278. SUGIMOTO, M. AND HIROKI, K., 2006. HybridTouch: An Intuitive Manipulation Technique for PDAs Using Their Front and Rear Surfaces In Proceedings of MobileHCI, 137–140.    System Design We present the LimpiDual Touch, which enables dual-sided touch sensing while seeing user’s fingers optically. The following chart shows the system design of LimpiDual Touch. To achieve our purpose, we focused on the Teraoka “ELEXY”, non-organic transparent EL display (the degree of transparency is 80%). The ELEXY has 256 x 120 pixels and displays 4 levels of brightness in umber color.\nWe attached two transparent touch panels (Datamate, the degree of transparency is 80%) on both sides of it, and these three panels are well calibrated. Using this system, the user can control displayed images from the rear side as well as the front side of the display. LimpiDual Touch has following features.\n The user can control information from the rear side of the display while optically seeing both the displayed images and their fingers. This characteristic can avoid the occlusion problem and brings new interactions by using both sides of the display. The LimpiDual Touch also works effectively for multiple users. More than two users can share the identical display and simultaneously control displayed objects from both sides of without the fingers colliding.    Application Prototyping We have created many idea sketches and developed two types of applications. One is for single user and the other is for two or more users facing across the display.\n  For single user, we implemented an application of layer manipulation. Information of mountains, regions and cities are overlaid on the map. The user can change the order of the layers by touching each side of the display, and select displayed additional information by touching specific points from the rear side of the display.\nFor multiple users, we implemented a “Tic-Tac-Toe” game application. In this application, players alternatively put marks (O or X) on a 3 x 3 grid. Two users can share the identical display while looking at the gestures or expressions each other. Such interactions between multiple users can be used for entertainment.\n  Development and Evaluation I demonstrated this sytem in public exhibitions and received many feedbacks from public.\nFuture work will be focused on improving mobility and expanding applications. It would be also important to evaluate utility and to design a good size of the system.\n  Result Honored by ACM SIGGRAPH I’ve proposed the emerging interactive transparent display named ‘‘LimpiDual Touch’’. Also, I’ve proved both-sided input had significant difference compared to front-side input as for the accuracy of touch input. In 2008, LimpiDual Touch was selected for ACM SIGGRAPH Student Research Competition and won the Japan Good Design Award.\nAwards \u0026amp; Honors  Selected for ACM SIGGRAPH Student Research Competition, 2008. Good Design Award of Japan, 2008. Young Researcher Award of Human Interface Society, 2009.  Publications  Masaki Iwabuchi, Yasuaki Kakehi, and Takeshi Naemura - \u0026ldquo;LimpiDual Touch, Interactive Limpid Display with Dual-sided Touch Sensing\u0026rdquo;, ACM SIGGRAPH2008 Posters, B156, Article no. 87 (2008.8). [ selected for Student Research Competition, ACM ] 岩渕 正樹, 筧 康明, 苗村 健 - ``LimpiDual Touchにおける両面タッチ入力の実験的検討\u0026rdquo;, 信学技報MVE2008-104, vol. 108, no. 379, pp. 45 \u0026ndash; 48 (2009.1) 岩渕 正樹, 筧 康明, 苗村 健 - ``LimpiDual Touch, 両面タッチ入力可能な透明インタラクティブディスプレイ\u0026rdquo;, ヒューマンインタフェースシンポジウム2008, 3424, pp. 1151 \u0026ndash; 1156 (2008.9). [学術奨励賞 受賞] 岩渕 正樹, 筧 康明, 苗村 健 - ``両面タッチ入力可能な透明インタラクティブディスプレイの基礎検討\u0026rdquo;, インタラクション2008, pp. 171 \u0026ndash; 172 (2008.3).  Exhibitions  iii exhibition 9, The University of Tokyo, Japan, 19-24 June, 2008. GOOD DESIGN EXPO 2008, Tokyo Big Sight, Japan 22-24 August, 2008. 50th Sign \u0026amp; Display Show, Tokyo Big Sight, Japan, 28-30 August, 2008. Interactive Tokyo, National museum of emerging science and innovation, Japan, 13-14 September, 2008.  ","date":1238126400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1238126400,"objectID":"5112deb79741150c0ca52b9cd6d5dbfe","permalink":"/project/2009_llimpidual/","publishdate":"2009-03-27T00:00:00-04:00","relpermalink":"/project/2009_llimpidual/","section":"project","summary":"Interactive limpid display with dual-sided touch sensing","tags":["product"],"title":"LimpiDual Touch","type":"project"}]